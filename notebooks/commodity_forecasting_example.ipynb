{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Commodity Price Forecasting - Example Notebook\n",
        "\n",
        "This notebook demonstrates the complete workflow for the commodity forecasting competition:\n",
        "1. Data loading and preprocessing\n",
        "2. Feature engineering\n",
        "3. Model training and evaluation\n",
        "4. Submission preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Import our modules\n",
        "from src.data_processing.data_loader import DataLoader, DEFAULT_DATA_FILES\n",
        "from src.feature_engineering.features import FeatureEngineer\n",
        "from src.models.ensemble_models import create_default_ensemble, create_custom_ensemble\n",
        "from src.evaluation.metrics import CompetitionMetrics, ModelValidator, evaluate_model_performance\n",
        "from src.utils.submission import CompetitionPipeline, ModelPersistence\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data loader\n",
        "data_loader = DataLoader(data_path=\"../data/\")\n",
        "\n",
        "# For demonstration, create sample data\n",
        "# In actual competition, you would load real data files\n",
        "\n",
        "def create_sample_data():\n",
        "    \"\"\"Create sample data for demonstration purposes.\"\"\"\n",
        "    \n",
        "    dates = pd.date_range(start='2020-01-01', end='2024-12-31', freq='D')\n",
        "    n_days = len(dates)\n",
        "    \n",
        "    # LME data (commodity prices)\n",
        "    lme_data = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'copper_price': 8000 + np.cumsum(np.random.randn(n_days) * 50),\n",
        "        'aluminum_price': 2000 + np.cumsum(np.random.randn(n_days) * 20),\n",
        "        'zinc_price': 3000 + np.cumsum(np.random.randn(n_days) * 30),\n",
        "    }).set_index('date')\n",
        "    \n",
        "    # JPX data (Japanese stocks)\n",
        "    jpx_data = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'nikkei_close': 25000 + np.cumsum(np.random.randn(n_days) * 200),\n",
        "        'topix_close': 1800 + np.cumsum(np.random.randn(n_days) * 15),\n",
        "    }).set_index('date')\n",
        "    \n",
        "    # US Stock data\n",
        "    us_stock_data = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'sp500_close': 4000 + np.cumsum(np.random.randn(n_days) * 50),\n",
        "        'nasdaq_close': 12000 + np.cumsum(np.random.randn(n_days) * 150),\n",
        "    }).set_index('date')\n",
        "    \n",
        "    # Forex data\n",
        "    forex_data = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'usd_jpy_rate': 110 + np.cumsum(np.random.randn(n_days) * 0.5),\n",
        "        'eur_usd_rate': 1.2 + np.cumsum(np.random.randn(n_days) * 0.01),\n",
        "    }).set_index('date')\n",
        "    \n",
        "    return {\n",
        "        'lme': lme_data,\n",
        "        'jpx': jpx_data,\n",
        "        'us_stock': us_stock_data,\n",
        "        'forex': forex_data\n",
        "    }\n",
        "\n",
        "# Create sample data\n",
        "sample_data = create_sample_data()\n",
        "\n",
        "# Display data info\n",
        "for market, df in sample_data.items():\n",
        "    print(f\"\\n{market.upper()} Data Shape: {df.shape}\")\n",
        "    print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align all data by common dates\n",
        "aligned_data = data_loader.align_data_by_date(sample_data)\n",
        "print(f\"Aligned data shape: {aligned_data.shape}\")\n",
        "print(f\"Date range: {aligned_data.index.min()} to {aligned_data.index.max()}\")\n",
        "\n",
        "# Clean data\n",
        "clean_data = data_loader.clean_data(aligned_data, fill_method='forward')\n",
        "print(f\"Clean data shape: {clean_data.shape}\")\n",
        "\n",
        "# Display first few rows\n",
        "clean_data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize feature engineer\n",
        "feature_engineer = FeatureEngineer()\n",
        "\n",
        "# Define asset pairs for price difference features\n",
        "asset_pairs = [\n",
        "    ('lme_copper_price', 'lme_aluminum_price'),\n",
        "    ('lme_copper_price', 'lme_zinc_price'),\n",
        "    ('jpx_nikkei_close', 'jpx_topix_close'),\n",
        "    ('us_stock_sp500_close', 'us_stock_nasdaq_close'),\n",
        "]\n",
        "\n",
        "# Define market prefixes\n",
        "market_prefixes = ['lme', 'jpx', 'us_stock', 'forex']\n",
        "\n",
        "# Build feature pipeline\n",
        "features = feature_engineer.build_feature_pipeline(\n",
        "    clean_data,\n",
        "    asset_pairs=asset_pairs,\n",
        "    market_prefixes=market_prefixes\n",
        ")\n",
        "\n",
        "print(f\"Features shape: {features.shape}\")\n",
        "print(f\"Number of features: {len(features.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create target variable - predict next day copper return\n",
        "target = clean_data['lme_copper_price'].pct_change().shift(-1)\n",
        "\n",
        "# Remove NaN values\n",
        "mask = ~(features.isnull().any(axis=1) | target.isnull())\n",
        "X = features[mask]\n",
        "y = target[mask]\n",
        "\n",
        "print(f\"Training data shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Target statistics:\")\n",
        "print(y.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "selected_features = feature_engineer.select_features(\n",
        "    X, y, \n",
        "    method='correlation', \n",
        "    max_features=50\n",
        ")\n",
        "\n",
        "X_selected = X[selected_features]\n",
        "print(f\"Selected features shape: {X_selected.shape}\")\n",
        "print(f\"Selected features: {selected_features[:10]}...\")  # Show first 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for training and testing\n",
        "split_date = '2024-01-01'\n",
        "train_mask = X_selected.index < split_date\n",
        "test_mask = X_selected.index >= split_date\n",
        "\n",
        "X_train, X_test = X_selected[train_mask], X_selected[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train ensemble model\n",
        "ensemble_model = create_default_ensemble()\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Ensemble model training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_train = ensemble_model.predict(X_train)\n",
        "y_pred_test = ensemble_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "train_metrics = evaluate_model_performance(y_pred_train, y_train.values)\n",
        "test_metrics = evaluate_model_performance(y_pred_test, y_test.values)\n",
        "\n",
        "print(\"Training Performance:\")\n",
        "for metric, value in train_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nTest Performance:\")\n",
        "for metric, value in test_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot predictions vs actual\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "\n",
        "# Training predictions\n",
        "axes[0].scatter(y_train.values, y_pred_train, alpha=0.5)\n",
        "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
        "axes[0].set_xlabel('Actual Returns')\n",
        "axes[0].set_ylabel('Predicted Returns')\n",
        "axes[0].set_title('Training Set: Predicted vs Actual Returns')\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Test predictions\n",
        "axes[1].scatter(y_test.values, y_pred_test, alpha=0.5, color='orange')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "axes[1].set_xlabel('Actual Returns')\n",
        "axes[1].set_ylabel('Predicted Returns')\n",
        "axes[1].set_title('Test Set: Predicted vs Actual Returns')\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Persistence and Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_metadata = {\n",
        "    'selected_features': selected_features,\n",
        "    'feature_engineer_config': {\n",
        "        'asset_pairs': asset_pairs,\n",
        "        'market_prefixes': market_prefixes\n",
        "    },\n",
        "    'performance_metrics': test_metrics,\n",
        "    'training_date_range': (X_train.index.min(), X_train.index.max()),\n",
        "    'test_date_range': (X_test.index.min(), X_test.index.max())\n",
        "}\n",
        "\n",
        "model_path = '../submissions/trained_ensemble_model.pkl'\n",
        "ModelPersistence.save_model(ensemble_model, model_path, model_metadata)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create competition pipeline and sample submission\n",
        "pipeline = CompetitionPipeline(ensemble_model, feature_engineer, data_loader)\n",
        "\n",
        "sample_submission = pd.DataFrame({\n",
        "    'id': range(len(y_test)),\n",
        "    'prediction': y_pred_test\n",
        "})\n",
        "\n",
        "submission_path = '../submissions/sample_submission.csv'\n",
        "sample_submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"Sample submission saved to {submission_path}\")\n",
        "print(sample_submission.head())\n",
        "\n",
        "# Validate submission format\n",
        "is_valid = pipeline.validate_submission(submission_path)\n",
        "print(f\"Submission validation: {'PASSED' if is_valid else 'FAILED'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary and Next Steps\n",
        "\n",
        "This notebook demonstrated the complete workflow for the commodity forecasting competition:\n",
        "\n",
        "### What we accomplished:\n",
        "1. ✅ Data loading and preprocessing from multiple markets\n",
        "2. ✅ Comprehensive feature engineering with price-difference series\n",
        "3. ✅ Ensemble model training with multiple algorithms\n",
        "4. ✅ Evaluation using competition metrics (Sharpe ratio variant)\n",
        "5. ✅ Model persistence and submission preparation\n",
        "\n",
        "### For the actual competition:\n",
        "1. Replace sample data with real competition datasets\n",
        "2. Tune hyperparameters using the validation framework\n",
        "3. Experiment with additional feature engineering techniques\n",
        "4. Test different ensemble configurations\n",
        "5. Implement the live submission pipeline\n",
        "\n",
        "### Key Performance Metrics:\n",
        "- **Competition Metric (Sharpe Variant)**: Primary evaluation criterion\n",
        "- **Spearman Correlation**: Ranking accuracy\n",
        "- **Directional Accuracy**: Trend prediction capability\n",
        "\n",
        "The framework is ready for competition deployment! 🚀\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
